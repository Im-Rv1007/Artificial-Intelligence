#Implementation of basic neural network model with 4 activation functions on Pima Indians onset of diabetes dataset.

import torch
import numpy as np
import torch.nn.functional as F

data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Dataset/diabetes.csv')
data.head()

inputs = torch.from_numpy(np.array(data.iloc[:, :-1])).float()
outputs = torch.from_numpy(np.array(data.iloc[:, -1])).float()
outputs.unique()

model = torch.nn.Sequential(
    torch.nn.Linear(8, 16),
    torch.nn.ReLU(),
    torch.nn.Linear(16, 32),
    torch.nn.Tanh(),
    torch.nn.Linear(32, 16),
    torch.nn.LeakyReLU(),
    torch.nn.Linear(16, 8),
    torch.nn.Sigmoid(),
    torch.nn.Linear(8, 1),
    torch.nn.Sigmoid(),
)

loss_fn = F.binary_cross_entropy
optimizer = torch.optim.SGD(model.parameters(), lr=0.00005)

model.train()
for t in range(1000):

    Y_pred = model(inputs)

    loss = loss_fn(Y_pred, outputs)
    
    if t % 100 == 0:
        print("Epoch:", t, "\tLoss:", loss.item())

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
print(torch.round(model(inputs[99])))
print(outputs[99])



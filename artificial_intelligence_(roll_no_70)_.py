# -*- coding: utf-8 -*-
"""Artificial Intelligence (Roll No. :- 70) .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TOxzxK47g2GEMwHbrtecbiL_ZRreZE9s

# **Practical No. 01**

**Graph**
"""

graph = {
  'Arad' : ['Sibiu', 'Timisoara', 'Zerind'],
  'Bucharest' : ['Fagaras', 'Giurgiu', 'Pitesti', 'Urziceni'],
  'Craiova' : ['Dobreta', 'Pitesti', 'Rimnicu Vilcea'],
  'Dobreta' : ['Craiova', 'Mehadia'],
  'Eforie' : ['Hirsova'],
  'Fagaras' : ['Sibiu', 'Bucharest'],
  'Giurgiu': ['Bucharest'],
  'Hirsova': ['Eforie', 'Urziceni'],
  'Iasi': ['Neamt', 'Vaslui'],
  'Lugoj': ['Mehadia', 'Timisoara'],
  'Mehadia': ['Dobreta', 'Lugoj'],
  'Oradea': ['Sibiu', 'Zerind'],
  'Pitesti': ['Bucharest', 'Craiova', 'Rimnicu Vilcea'],
  'Rimnicu Vilcea': ['Craiova','Pitesti', 'Sibiu'],
  'Sibiu': ['Arad', 'Fagaras', 'Rimnicu Vilcea', 'Oradea'],
  'Timisoara': ['Arad', 'Lugoj'],
  'Urziceni': ['Bucharest', 'Hirsova', 'Iasi'],
  'Vaslui': ['Iasi', 'Urziceni'],
  'Zerind': ['Arad', 'Oradea'],
  'Neamt': ['Iasi']
}

"""## **1. Implement Breadth First Search (BFS) algorithm**"""

def bfs_shortest_path(graph, start, goal):
    # keep track of explored nodes
    explored = []
    # keep track of all the paths to be checked
    queue = [[start]]
 
    # return path if start is goal
    if start == goal:
        return "That was easy! Start = goal"
 
    # keeps looping until all possible paths have been checked
    while queue:
        # pop the first path from the queue
        path = queue.pop(0)
        # get the last node from the path
        node = path[-1]
        if node not in explored:
            neighbours = graph[node]
            # go through all neighbour nodes, construct a new path and
            # push it into the queue
            for neighbour in neighbours:
                new_path = list(path)
                new_path.append(neighbour)
                queue.append(new_path)
                # return path if neighbour is goal
                if neighbour == goal:
                    return new_path
 
            # mark node as explored
            explored.append(node)
 
    # in case there's no path between the 2 nodes
    return "So sorry, but a connecting path doesn't exist :("
 
bfs_shortest_path(graph, 'Arad', 'Fagaras')

"""## **2. Implement Depth First Search (DFS) algorithm**"""

def dfs_shortest_path(graph, source, dest):
  stack = [(source, [source])]; visited = set()

  while stack:
    (v, path) = stack.pop()
    if v not in visited:
      if v == dest:
        return path
      visited.add(v)
      for node in graph[v]:
        stack.append((node, path+[node]))

dfs_shortest_path(graph, 'Arad', 'Fagaras')

"""## **3. Implement Iterative deepening Search (IDS) algorithm**"""



"""# **Practical No. 02**

## **1. Implement A* search algorithm**
"""

import pandas as pd
from math import sqrt

map = {
    "Name":{
        "0":"Arad","1":"Bucharest","2":"Craiova",
        "3":"Drobeta","4":"Eforie","5":"Fagaras",
        "6":"Giurgiu","7":"Hirsova","8":"Iasi",
        "9":"Lugoj","10":"Mehadia","11":"Neamt",
        "12":"Oradea","13":"Pitesti","14":"Rimnicu Vilcea",
        "15":"Sibiu","16":"Timisoara","17":"Urziceni",
        "18":"Vaslui","19":"Zerind"
        },
     "X":{
         "0":62,"1":560,"2":319,"3":177,"4":824,"5":409,"6":518,
          "7":777,"8":680,"9":175,"10":182,"11":571,"12":121,"13":434,
          "14":290,"15":244,"16":67,"17":649,"18":735,"19":86
          },
     "Y":{"0":144,"1":409,"2":478,"3":463,"4":469,"5":217,"6":507,
          "7":378,"8":122,"9":333,"10":394,"11":73,"12":19,"13":353,
          "14":281,"15":202,"16":282,"17":376,"18":222,"19":83
          }
     }

distances = {
    "A":{
        "0":"Arad","1":"Arad","2":"Arad","3":"Bucharest","4":"Bucharest","5":"Craiova",
        "6":"Craiova","7":"Drobeta","8":"Fagaras","9":"Hirsova","10":"Iasi","11":"Lugoj",
        "12":"Mehadia","13":"Oradea","14":"Timisoara","15":"Pitesti","16":"Rimnicu Vilcea",
        "17":"Sibiu","18":"Sibiu","19":"Urziceni","20":"Urziceni","21":"Vaslui","22":"Zerind",
        "23":"Zerind","24":"Timisoara","25":"Sibiu","26":"Giurgiu","27":"Urziceni","28":"Rimnicu Vilcea",
        "29":"Pitesti","30":"Craiova","31":"Bucharest","32":"Eforie","33":"Neamt","34":"Mehadia","35":"Drobeta",
        "36":"Sibiu","37":"Lugoj","38":"Bucharest","39":"Pitesti","40":"Fagaras",
        "41":"Rimnicu Vilcea","42":"Vaslui","43":"Hirsova","44":"Iasi","45":"Oradea"},
    "B":{
        "0":"Zerind","1":"Timisoara","2":"Sibiu","3":"Giurgiu","4":"Urziceni","5":"Rimnicu Vilcea",
        "6":"Pitesti","7":"Craiova","8":"Bucharest","9":"Eforie","10":"Neamt","11":"Mehadia","12":"Drobeta",
        "13":"Sibiu","14":"Lugoj","15":"Bucharest","16":"Pitesti","17":"Fagaras","18":"Rimnicu Vilcea","19":"Vaslui",
        "20":"Hirsova","21":"Iasi","22":"Oradea","23":"Arad","24":"Arad","25":"Arad","26":"Bucharest",
        "27":"Bucharest","28":"Craiova","29":"Craiova","30":"Drobeta","31":"Fagaras","32":"Hirsova","33":"Iasi",
        "34":"Lugoj","35":"Mehadia","36":"Oradea","37":"Timisoara","38":"Pitesti","39":"Rimnicu Vilcea","40":"Sibiu",
        "41":"Sibiu","42":"Urziceni","43":"Urziceni","44":"Vaslui","45":"Zerind"},
    "Distance":{
        "0":75,"1":118,"2":140,"3":90,"4":85,"5":146,"6":138,"7":120,"8":211,"9":86,"10":87,"11":70,"12":75,"13":151,
        "14":111,"15":101,"16":97,"17":99,"18":80,"19":142,"20":98,"21":92,"22":71,"23":75,"24":118,"25":140,"26":90,
        "27":85,"28":146,"29":138,"30":120,"31":211,"32":86,"33":87,"34":70,"35":75,"36":151,"37":111,"38":101,"39":97,
        "40":99,"41":80,"42":142,"43":98,"44":92,"45":71
        }
      }

places_coord = pd.DataFrame.from_dict(map)
distance_route = pd.DataFrame.from_dict(distances)

def heuristic(node, dest):
  if node == dest:
    return 0
  else:
    x_dist = (places_coord.loc[places_coord['Name'] == node].X.item() - places_coord.loc[places_coord['Name'] == dest].X.item()) ** 2
    y_dist = (places_coord.loc[places_coord['Name'] == node].Y.item() - places_coord.loc[places_coord['Name'] == dest].Y.item()) ** 2 
    return int(sqrt(x_dist + y_dist))

def curr_forw(curr_node, final_dest):
  h = [] # heruistic added with curr_node to next_spot dist
  pl = [] # names of all places
  global distances
  if curr_node == final_dest:
    return curr_node, 0
  places = distance_route.loc[distance_route['A'] == curr_node]
  print('Current Node: ', curr_node)
  for place in places.itertuples():
    if place.B not in closed_list:
      pl.append(place.B)
      print(place.B, ' || edge: ', place.Distance, ' ; weight so far: ', distances, ' ; heuristic:  ', heuristic(place.B, final_dest))
      h.append(distances + place.Distance + heuristic(place.B, final_dest)) # weights added but path not optimal
  print('\n')
  next_spot = pl[h.index(min(h))]
  # distances += places.loc[places['B'] == next_spot].Distance.item()
  return next_spot, places.loc[places['B'] == next_spot].Distance.item()


def a_star(source, dest):
  global distances
  if source == dest:
    return dest
  open_list.append(source)
  while len(open_list) > 0:
    n, h_val = curr_forw(open_list[0], dest)
    if n == dest:
      distances += h_val
      s = open_list.pop(0)
      closed_list.append(s)
      closed_list.append(dest)
      return closed_list
    distances += h_val
    s = open_list.pop(0)
    open_list.append(n)
    closed_list.append(s)
  return closed_list


open_list = []
closed_list = []
distances = 0 # weights summed till curr-1 node from source
print(a_star('Arad', 'Neamt'))

# the path isnt optimal as the heuristic underestimates the admissibility based on the given coordinates, and that might be the actual issue
# else the algorithm works, and the code remains correct

"""## **2. Implement recursive best-first search algorithm**"""



"""# **Practical No. 03**

## **Implementation of Neural Net on IRIS dataset**
"""

!pip install pandas

import pandas as pd

from google.colab import drive
drive.mount('/content/drive/')

iris = pd.read_csv('/content/drive/My Drive/Colab Notebooks/iris_csv.csv')
iris.head()

from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
X, y = load_iris(return_X_y=True)
clf = LogisticRegression(random_state=0).fit(X, y)
clf.predict(X[:2, :])
clf.predict_proba(X[:2, :])
clf.score(X, y)

clf.predict(X)

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn import datasets
from sklearn.decomposition import PCA

# import some data to play with
iris = datasets.load_iris()
X = iris.data[:, :2]  # we only take the first two features.
y = iris.target

x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5
y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5

plt.figure(2, figsize=(8, 6))
plt.clf()

# Plot the training points
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1,
            edgecolor='k')
plt.xlabel('Sepal length')
plt.ylabel('Sepal width')

plt.xlim(x_min, x_max)
plt.ylim(y_min, y_max)
plt.xticks(())
plt.yticks(())

# To getter a better understanding of interaction of the dimensions
# plot the first three PCA dimensions
fig = plt.figure(1, figsize=(8, 6))
ax = Axes3D(fig, elev=-150, azim=110)
X_reduced = PCA(n_components=3).fit_transform(iris.data)
ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=y,
           cmap=plt.cm.Set1, edgecolor='k', s=40)
ax.set_title("First three PCA directions")
ax.set_xlabel("1st eigenvector")
ax.w_xaxis.set_ticklabels([])
ax.set_ylabel("2nd eigenvector")
ax.w_yaxis.set_ticklabels([])
ax.set_zlabel("3rd eigenvector")
ax.w_zaxis.set_ticklabels([])

plt.show()

"""# **Practical No. 04**

## **Implementation of basic neural network model with 4 activation functions on Pima Indians onset of diabetes dataset.**
"""

import torch
import numpy as np
import torch.nn.functional as F

data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Dataset/diabetes.csv')
data.head()

inputs = torch.from_numpy(np.array(data.iloc[:, :-1])).float()
outputs = torch.from_numpy(np.array(data.iloc[:, -1])).float()
outputs.unique()

model = torch.nn.Sequential(
    torch.nn.Linear(8, 16),
    torch.nn.ReLU(),
    torch.nn.Linear(16, 32),
    torch.nn.Tanh(),
    torch.nn.Linear(32, 16),
    torch.nn.LeakyReLU(),
    torch.nn.Linear(16, 8),
    torch.nn.Sigmoid(),
    torch.nn.Linear(8, 1),
    torch.nn.Sigmoid(),
)

loss_fn = F.binary_cross_entropy
optimizer = torch.optim.SGD(model.parameters(), lr=0.00005)

model.train()
for t in range(1000):

    Y_pred = model(inputs)

    loss = loss_fn(Y_pred, outputs)
    
    if t % 100 == 0:
        print("Epoch:", t, "\tLoss:", loss.item())

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

print(torch.round(model(inputs[99])))
print(outputs[99])

"""# **Practical No. 05**

## **Performing AND & OR Operations in the Neural Network**
"""

import numpy as np

def unitStep(v):
  if v >= 0:
    return 1
  else:
    return 0

def pm(x,w,b):
  v=np.dot(w,x)+b
  y= unitStep(v)
  return y

def or_logic(x):
  w=np.array([1,1])
  b= -0.5
  return pm(x,w,b)

def and_logic(x):
  w=np.array([1,1])
  b= -1.5
  return pm(x,w,b)


#and functiion -1.5 bias

test1= np.array([0,0])
test2= np.array([0,1])
test3= np.array([1,0])
test4= np.array([1,1])
print("OR GATE")
print("or first({},{})={}:".format(0,0,or_logic(test1)))
print("or second({},{})={}:".format(0,1,or_logic(test2)))
print("or third({},{})={}:".format(1,0,or_logic(test3)))
print("or fourth({},{})={}:".format(1,1,or_logic(test4)))
print("")
print("AND GATE")
print("or first({},{})={}:".format(0,0,and_logic(test1)))
print("or second({},{})={}:".format(0,1,and_logic(test2)))
print("or third({},{})={}:".format(1,0,and_logic(test3)))
print("or fourth({},{})={}:".format(1,1,and_logic(test4)))
print("")

"""# **Practical No. 06**

## **Prediction Algorithm - Use of different packages on dataset of Cat and Non-Cat images.**

# **Practical No. 07**

## **Classify errors and its different types**

# **Practical No. 08**

## **Simple Linear Regression**

# **Practical No. 09**

## **Implement Support Vector Algorithm**

# **Practical No. 10**

## **Implement decision tree learning algorithm**

# **Practical No. 11**

## **Implement Adaboost ensemble learning algorithm**
"""